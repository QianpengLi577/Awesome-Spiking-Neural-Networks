# Awesome Spiking Neural Networks [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

This repo collects papers, docs, codes about spiking neural networks for anyone who wants to do research on it. We are continuously improving the project. Welcome to PR the works (papers, repositories) that are missed by the repo. Special thanks to [Yifu Ding](https://yifu-ding.github.io/#/), [Xudong Ma](https://github.com/Macaronlin), [Yuxuan Wen](https://github.com/ChrisLeff), and all researchers who have contributed to this project!

## Table of Contents

- [Survey Papers](#Survey_Papers)
  - [Survey_of_Direct_Training_Method](#Survey_of_Direct_Training_Method)
  - [Survey_of_ANN-SNN](#Survey_of_ANN-SNN)
- [Papers](#Papers)
  - [2023](#2023)
  - [2022](#2022)
  - [2021](#2021)
  - [2020](#2020)
  - [2019](#2019)
  - [2018](#2018)
  - [2017](#2017)
  - [2016](#2016)
  - [2015](#2015)
- [Codes and Docs](#Codes_and_Docs)
- [Our Team](#Our_Team)

## Survey_Papers

### Survey_of_Direct_Training_Method

Our survey paper **Direct Learning-Based Deep Spiking Neural Networks: A Review** (_Frontiers in Neuroscience_) is a comprehensive survey of recent progress in directly training spiking neural networks. For details, please refer to:

**Direct Learning-Based Deep Spiking Neural Networks: A Review** [[Paper](https://arxiv.org/abs/2305.19725)]

[**Yufei Guo**](https://yfguo91.github.io/), Xuhui Huang, and Zhe Ma.

<details><summary>Bibtex</summary><pre><code>@article{guo2023direct,
  title={Direct learning-based deep spiking neural networks: a review},
  author={Guo, Yufei and Huang, Xuhui and Ma, Zhe},
  journal={Frontiers in Neuroscience},
  volume={17},
  pages={1209795},
  year={2023},
  publisher={Frontiers}
}</code></pre></details>


### Survey_of_ANN-SNN

The survey paper 

## Papers

### 2023

- [[ICML](https://openreview.net/pdf?id=GdkwSGTpbC)] Adaptive Smoothing Gradient Learning for Spiking Neural Networks
- [[ICML](https://openreview.net/pdf?id=zRkz4duLKp)] Surrogate Module Learning: Reduce the Gradient Error Accumulation in Training Spiking Neural Networks [[code](https://github.com/brain-intelligence-lab/surrogate_module_learning)]


### 2022

- [[NeurIPS](https://arxiv.org/pdf/2210.13768.pdf)] GLIF: A Unified Gated Leaky Integrate-and-Fire Neuron for Spiking Neural Networks [[code](https://github.com/Ikarosy/Gated-LIF)]
- [[NeurIPS](https://arxiv.org/pdf/2206.04426.pdf)] Biologically Inspired Dynamic Thresholds for Spiking Neural Networks
- [[NeurIPS](https://arxiv.org/pdf/2210.04195.pdf)] Online Training Through Time for Spiking Neural Networks [[code](https://github.com/pkuxmq/OTTT-SNN)]
- [[NeurIPS](https://arxiv.org/pdf/2205.13493.pdf)] Mesoscopic modeling of hidden spiking neurons
- [[NeurIPS](https://openreview.net/pdf?id=fLIgyyQiJqz)] Temporal Effective Batch Normalization in Spiking Neural Networks
- [[NeurIPS](https://openreview.net/pdf?id=Lr2Z85cdvB)] Differentiable hierarchical and surrogate gradient search for spiking neural networks 
- [[NeurIPS](https://openreview.net/pdf?id=BbaSRgUHW3)] LTMD: Learning Improvement of Spiking Neural Networks with Learnable Thresholding Neurons and Moderate Dropout
- [[NeurIPS](https://openreview.net/pdf?id=I0CiI7Oyp1E)] Theoretically Provable Spiking Neural Networks
- [[NeurIPS](https://openreview.net/pdf?id=Yopob26XjmL)] Natural gradient enables fast sampling in spiking neural networks
- [[NeurIPS](https://openreview.net/pdf?id=zdmYnIRXvKS)] Biologically plausible solutions for spiking networks with efficient coding
- [[NeurIPS](https://openreview.net/pdf?id=Ncyc0JS7Q16)] Toward Robust Spiking Neural Network Against Adversarial Perturbation
- [[NeurIPS](https://openreview.net/pdf?id=xwBdjfKt7_W)] SNN-RAT: Robustness-enhanced Spiking Neural Network through Regularized Adversarial Training
- [[NeurIPS](https://openreview.net/pdf?id=xwBdjfKt7_W)] Emergence of Hierarchical Layers in a Single Sheet of Self-Organizing Spiking Neurons
- [[NeurIPS](https://openreview.net/pdf?id=d4JmP1T45WE)] Training Spiking Neural Networks with Event-driven Backpropagation
- [[NeurIPS](https://openreview.net/pdf?id=Jw34v_84m2b)] IM-Loss: Information Maximization Loss for Spiking Neural Networks [[code](https://github.com/yfguo91/IM-Loss-Information-Maximization-Loss-for-Spiking-Neural-Networks)]
- [[NeurIPS](https://openreview.net/pdf?id=ckQvYXizgd1)] The computational and learning benefits of Daleian neural networks
- [[NeurIPS](https://openreview.net/pdf?id=-yiZR4_Xhh)] Dance of SNN and ANN: Solving binding problem by combining spike timing and reconstructive attention
- [[NeurIPS](https://openreview.net/pdf?id=3vYkhJIty7E)] Learning Optical Flow from Continuous Spike Streams [[code](https://github.com/ruizhao26/Spike2Flow)]
- [[NeurIPS](https://openreview.net/pdf?id=iUOUnyS6uTf)] STNDT: Modeling Neural Population Activity with Spatiotemporal Transformers
- [[AAAI](https://arxiv.org/pdf/2202.01440.pdf)] Optimized Potential Initialization for Low-latency Spiking Neural Networks
- [[AAAI](https://arxiv.org/pdf/2104.03414.pdf)] PrivateSNN: Privacy-Preserving Spiking Neural Networks







## Codes_and_Docs

- [[中文](https://blog.csdn.net/qq_43622216/article/details/124163883)] 2022年顶会、顶刊SNN相关论文

## Our_Team

Our team .


### Publications



